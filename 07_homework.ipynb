{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00fad453",
      "metadata": {
        "id": "00fad453"
      },
      "source": [
        "# Домашнее задание № 3. Языковые модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d056af4",
      "metadata": {
        "id": "5d056af4"
      },
      "source": [
        "## Задание 1 (8 баллов)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f532a8",
      "metadata": {
        "id": "d1f532a8"
      },
      "source": [
        "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de743d1d",
      "metadata": {
        "id": "de743d1d"
      },
      "source": [
        "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
        "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели.\n",
        "Можно использовать данные из семинара или любые другие (можно брать только часть текста, если считается слишком долго). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
        "\n",
        "\n",
        "Подсказки:  \n",
        "    - нужно будет добавить еще один тэг \\<start>  \n",
        "    - можете использовать тот же подход с матрицей вероятностей, но по строкам хронить биграмы, а по колонкам униграммы\n",
        "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)\n",
        "    - у вас будут словари с индексами биграммов и униграммов, не перепутайте их при переводе индекса в слово - словарь биграммов будет больше словаря униграммов и все индексы из униграммного словаря будут формально подходить для словаря биграммов (не будет ошибки при id2bigram[unigram_id]), но маппинг при этом будет совершенно неправильным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lbOoYIYZaX9C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbOoYIYZaX9C",
        "outputId": "08d99d5c-89f8-42c5-b8c5-00d61816ae4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7qM7dgqd-b-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7qM7dgqd-b-",
        "outputId": "440eeb9d-3771-4175-9716-2104be348de5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bpSPkfpsaWiK",
      "metadata": {
        "id": "bpSPkfpsaWiK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6afcef88",
      "metadata": {
        "id": "6afcef88",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"cointegrated/taiga_stripped_rest\", split='Fontanka')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw3-by8gbENL",
        "outputId": "c7afdb5f-6267-4440-d067-428971a8594b"
      },
      "id": "aw3-by8gbENL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '«Газпром» и Белоруссия подписали соглашение о поставках российского газа.\\nКак передает ИА «Регнум», глава компании Алексей Миллер сообщил журналистам подробности соглашения.\\n\\nЦена российского газа для Белоруссии составит с 1 января 100 долларов США за 1000 кубометров и в дальнейшем будет рассчитываться по формуле цены, установленной в контракте. К 2011 году она вырастет до среднеевропейского уровня. \\n\\nСтоимость транспортировки российского газа по территории Белоруссии вырастет с нынешних 0,75 доллара США за 1000 кубометров на 100 километров до 1,45 доллара США и будет зафиксирована на все пять лет действия контракта. \\n\\n\"Газпром\" в ближайшие 4 года выкупит 50% акций \"Белтрансгаза\" за 2,5 миллиарда долларов в течение 4 лет. \\n\\nПоследние переговоры между сторонами прошли вчера в Москве.\\n                ',\n",
              " 'file': 'Fontanka/texts/2007/fontanka_20070101001.txt'}"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fontanka_data = []\n",
        "for elem in ds:\n",
        "    fontanka_data.append(elem['text'])\n",
        "fontanka_data = '\\n'.join(fontanka_data)"
      ],
      "metadata": {
        "id": "CQnOqJeHYbCI"
      },
      "id": "CQnOqJeHYbCI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fontanka_data = fontanka_data[:40000000]"
      ],
      "metadata": {
        "id": "L9MfMxmeb6Kd"
      },
      "id": "L9MfMxmeb6Kd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ndxn7FL-c0yN",
      "metadata": {
        "id": "ndxn7FL-c0yN"
      },
      "outputs": [],
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [word.text for word in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13Y2CZJldngA",
      "metadata": {
        "id": "13Y2CZJldngA"
      },
      "outputs": [],
      "source": [
        "sentences_fontanka = [['<start>', '<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(fontanka_data)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = sentences_fontanka[:-50]"
      ],
      "metadata": {
        "id": "5bZijQSUXWEs"
      },
      "id": "5bZijQSUXWEs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = sentences_fontanka[-50:]"
      ],
      "metadata": {
        "id": "Oa6F8A59WkR_"
      },
      "id": "Oa6F8A59WkR_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences_fontanka)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r26JwFerXbSO",
        "outputId": "2083fa13-c96d-4911-ff2f-9e5e0580ac51"
      },
      "id": "r26JwFerXbSO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "322861"
            ]
          },
          "metadata": {},
          "execution_count": 505
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pxo_vdhXY7v",
        "outputId": "54a00428-b64f-46cd-c7b2-c007470958ab"
      },
      "id": "8pxo_vdhXY7v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "322811"
            ]
          },
          "metadata": {},
          "execution_count": 506
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO7-ofE8XZ4q",
        "outputId": "b0528cf8-9cd7-487e-f7eb-595d25702da5"
      },
      "id": "uO7-ofE8XZ4q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 507
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sFuQBoqNf6VD",
      "metadata": {
        "id": "sFuQBoqNf6VD"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import lil_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzYuPbyIdaNg",
        "outputId": "061001df-c2c4-4ba0-ddab-b7be3c89e0ad"
      },
      "id": "dzYuPbyIdaNg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start>',\n",
              " '<start>',\n",
              " '«',\n",
              " 'газпром',\n",
              " '»',\n",
              " 'и',\n",
              " 'белоруссия',\n",
              " 'подписали',\n",
              " 'соглашение',\n",
              " 'о',\n",
              " 'поставках',\n",
              " 'российского',\n",
              " 'газа',\n",
              " '.',\n",
              " '<end>']"
            ]
          },
          "metadata": {},
          "execution_count": 509
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rp3XLD_zfOI7",
      "metadata": {
        "id": "Rp3XLD_zfOI7"
      },
      "outputs": [],
      "source": [
        "unigrams = Counter()\n",
        "bigrams = Counter()\n",
        "trigrams = Counter()\n",
        "\n",
        "for sent in train:\n",
        "    for i in range(len(sent)):\n",
        "        unigrams[sent[i]] += 1\n",
        "        if i>=1:\n",
        "            bigrams[(sent[i-1], sent[i])] += 1\n",
        "        if i>=2:\n",
        "            trigrams[(sent[i-2], sent[i-1], sent[i])] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2gkFe_uguyV",
      "metadata": {
        "id": "b2gkFe_uguyV"
      },
      "outputs": [],
      "source": [
        "id2word = list(unigrams)\n",
        "word2id = {word:i for i, word in enumerate(id2word)}\n",
        "id2bigram = list(bigrams)\n",
        "bigram2id = {bg:i for i,bg in enumerate(id2bigram)}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BW_vWLG6oL0e",
      "metadata": {
        "id": "BW_vWLG6oL0e"
      },
      "source": [
        "$P(w3​∣w1​,w2​)=\\frac{count(w1​,w2​)}{count(w1​,w2​,w3​)}​$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# основная матрица: биграммы на униграммы\n",
        "matrix = lil_matrix((len(bigrams), len(unigrams)))\n",
        "for (w1, w2, w3), count in trigrams.items():\n",
        "    row = bigram2id[(w1, w2)]\n",
        "    col = word2id[w3]\n",
        "    matrix[row, col] = count / bigrams[(w1, w2)]\n",
        "matrix[0,5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhGwfNJ9GZJl",
        "outputId": "10a839e3-ca2d-48b0-bbd5-c95dfe797469"
      },
      "id": "PhGwfNJ9GZJl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(9.29336360904678e-06)"
            ]
          },
          "metadata": {},
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# матрица: униграммы на униграммы\n",
        "bigram_matrix = lil_matrix((len(unigrams), len(unigrams)))\n",
        "for (w1, w2), count in bigrams.items():\n",
        "    i, j = word2id[w1], word2id[w2]\n",
        "    bigram_matrix[i,j] = count / unigrams[w1]"
      ],
      "metadata": {
        "id": "WB1T56clEgeW"
      },
      "id": "WB1T56clEgeW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вероятность просто отдельного слова\n",
        "count_all_words = sum(unigrams.values())\n",
        "unigram_probs = np.array([unigrams[w] / count_all_words for w in id2word], dtype=float)\n",
        "unigram_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TpNjJ03GCWt",
        "outputId": "68aae61f-c6ae-494c-94bf-9c429ee734b2"
      },
      "id": "-TpNjJ03GCWt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8.65206586e-02, 1.43095951e-02, 9.17977565e-05, ...,\n",
              "       1.34011323e-07, 1.34011323e-07, 1.34011323e-07])"
            ]
          },
          "metadata": {},
          "execution_count": 514
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_temperature(probas, temperature):\n",
        "    log_probas = np.log(np.maximum(probas, 1e-10))\n",
        "    adjusted_log_probas = log_probas / temperature\n",
        "    exp_probas = np.exp(adjusted_log_probas)\n",
        "    adjusted_probabilities = exp_probas / np.sum(exp_probas)\n",
        "    return adjusted_probabilities"
      ],
      "metadata": {
        "id": "6Rv7is7iD8p7"
      },
      "id": "6Rv7is7iD8p7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(matrix, id2bigram, id2word, bigram2id, word2id, bigram_matrix, unigram_probs,\n",
        "            n=600, temperature=0.9, backoff_threshold=1e-10):\n",
        "    w1, w2 = '<start>', '<start>'\n",
        "    text = []\n",
        "    sentence = []\n",
        "    for i in range(n):\n",
        "        row_idx = bigram2id.get((w1, w2))\n",
        "        probs = None\n",
        "        if row_idx is not None:\n",
        "            probs = matrix[row_idx].toarray()[0]\n",
        "            # если для данной биграммы совсем маленькая вероятность\n",
        "            # то переходим к биграмной матрице\n",
        "            if probs.max() < backoff_threshold:\n",
        "                probs = None\n",
        "        if probs is None:\n",
        "            idx_w2 = word2id.get(w2)\n",
        "            if idx_w2 is not None:\n",
        "                probs = bigram_matrix[idx_w2].toarray()[0]\n",
        "            else:\n",
        "                row_idx = bigram2id.get(('<start>', w2))\n",
        "                if row_idx is None:\n",
        "                    probs = unigram_probs\n",
        "\n",
        "        chosen_idx = np.random.choice(matrix.shape[1], p=apply_temperature(probs, temperature=temperature))\n",
        "        chosen_word = id2word[chosen_idx]\n",
        "        if chosen_word == '.' and len(sentence) <= 3:\n",
        "            breaking_point = 0\n",
        "            while True:\n",
        "                if breaking_point == 100:\n",
        "                    break\n",
        "                chosen_idx = np.random.choice(matrix.shape[1],\n",
        "                                                  p=apply_temperature(probs, temperature=0.9))\n",
        "                chosen_word = id2word[chosen_idx]\n",
        "                if chosen_word != '.':\n",
        "                    break\n",
        "                breaking_point += 1\n",
        "\n",
        "        if chosen_word == '<end>':\n",
        "            final_sentence = ' '.join(sentence).capitalize()\n",
        "            text.append(f'{final_sentence}<end>')\n",
        "            sentence = []\n",
        "            if n - i < 10:\n",
        "                break\n",
        "        else:\n",
        "            sentence.append(chosen_word)\n",
        "        w1, w2 = w2, chosen_word\n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "8FSJIxcx_a9F"
      },
      "id": "8FSJIxcx_a9F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "for _ in range(5):\n",
        "    texts.append(generate(matrix, id2bigram, id2word, bigram2id, word2id,\n",
        "               bigram_matrix, unigram_probs, temperature=0.65, n=100).replace('<end>', ' '))"
      ],
      "metadata": {
        "id": "GU2yl8U3Cd_M"
      },
      "id": "GU2yl8U3Cd_M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(logp, N):\n",
        "    return np.exp((-1/N) * logp)"
      ],
      "metadata": {
        "id": "4ktCmkofg2Ln"
      },
      "id": "4ktCmkofg2Ln",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_join_proba_trigrams(seq, unigram_counts, bigram_counts, trigram_counts):\n",
        "    log_prob = 0.0\n",
        "    for i in range(2, len(seq)):\n",
        "        w1, w2, w3 = seq[i-2], seq[i-1], seq[i]\n",
        "\n",
        "        bigram = (w1, w2)\n",
        "        trigram = (w1, w2, w3)\n",
        "\n",
        "        if bigram in bigram_counts and trigram in trigram_counts:\n",
        "            p = trigram_counts[trigram] / bigram_counts[bigram]\n",
        "            log_prob += np.log(p)\n",
        "        else:\n",
        "            log_prob += np.log(2e-6)\n",
        "\n",
        "    return log_prob, len(seq[2:-1])"
      ],
      "metadata": {
        "id": "yx7Ze54JhVfi"
      },
      "id": "yx7Ze54JhVfi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_joint_proba(tokens, word_probas):\n",
        "    prob = 0\n",
        "    for word in tokens:\n",
        "        if word in word_probas:\n",
        "            prob += (np.log(word_probas[word]))\n",
        "        else:\n",
        "            prob += np.log(2e-4)\n",
        "\n",
        "    return prob, len(tokens[2:-1])\n",
        "\n",
        "\n",
        "def compute_join_proba_markov_assumption(tokens, word_counts, bigram_counts):\n",
        "    prob = 0\n",
        "    for i in range(1, len(tokens)):\n",
        "        w1, w2 = tokens[i-1], tokens[i]\n",
        "        if w1 in word_counts and w2 in bigram_counts:\n",
        "            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n",
        "        else:\n",
        "            prob += np.log(2e-5)\n",
        "\n",
        "    return prob, len(tokens[2:-1])"
      ],
      "metadata": {
        "id": "TXkdKpiqnumv"
      },
      "id": "TXkdKpiqnumv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results_trigrams = []\n",
        "all_results_bigrams = []\n",
        "all_results_uni = []\n",
        "for phrase in test:\n",
        "    log_prob, tokens_length = compute_join_proba_trigrams(phrase, unigrams, bigrams, trigrams)\n",
        "    all_results_trigrams.append(perplexity(log_prob, tokens_length))\n",
        "    log_prob, tokens_length = compute_join_proba_markov_assumption(phrase, unigrams, bigrams)\n",
        "    all_results_bigrams.append(perplexity(log_prob, tokens_length))\n",
        "    log_prob, tokens_length = compute_joint_proba(phrase, unigram_probs)\n",
        "    all_results_uni.append(perplexity(log_prob, tokens_length))"
      ],
      "metadata": {
        "id": "sdyQxKAqiYzF"
      },
      "id": "sdyQxKAqiYzF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'По триграммам перплексия: {np.mean(all_results_trigrams)}')\n",
        "print(f'По биграммам перплексия: {np.mean(all_results_bigrams)}')\n",
        "print(f'По униграммам перплексия: {np.mean(all_results_uni)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9MkgUmxjjH2",
        "outputId": "48e0d9c4-b1cd-4e30-cdd3-b2d53e742ae2"
      },
      "id": "v9MkgUmxjjH2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "По триграммам перплексия: 32236.708598509824\n",
            "По биграммам перплексия: 218078.45827201704\n",
            "По униграммам перплексия: 30294.50888753311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "VScs1yBTrdNh"
      },
      "id": "VScs1yBTrdNh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cpeel0-prmDr",
        "outputId": "2fd320a9-872b-47c5-9411-fc497a0db056"
      },
      "id": "cpeel0-prmDr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 539
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_texts(text):\n",
        "    text = re.sub(' (?=[!#&*+,.»/:;?]+)', '', text)\n",
        "    text = re.sub('(?<=«) ', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "n6WwGNS9rIhm"
      },
      "id": "n6WwGNS9rIhm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{'◦'*50} Полученные тексты {'◦'*50}')\n",
        "for text in texts:\n",
        "    print(normalize_texts(text))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3FB2LnzpGRM",
        "outputId": "f339a146-50ac-4a0e-b570-9ede4ad78f8b"
      },
      "id": "e3FB2LnzpGRM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦ Полученные тексты ◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦\n",
            "В приморском районе стреляли в легковую машину риа «новости».  Adsl-модем всем своим видом давал понять присутствующим, что в течение того же года с инсталляцией пра-образы в art-галерее 103 на пушкинской улице вернулось в московский городской суд санкт-петербурга отказал в иске к «».  Перевыполнить!  Сочиненную одной из крупнейших музейных комплексов, то есть в качестве официального периодического издания, которые в принципе, все с простого человека, который будет способствовать развитию этой компании. \n",
            "\n",
            "Нам же известно и о странных и злых людях, которые они оказывали ему медпомощь.  Шлем, в городе на неве, а другие - пятизвездочный отель etc, ориентирована отнюдь не на “ лакомый кусок ” в конце апреля, и в метро?  Безотлагательные меры по предупреждению и ликвидации последствий аварии: вторая в городе и ленобласти, это была целая эпопея, - заявила «фонтанке» в пресс-службе завода. \n",
            "\n",
            "По словам источника, сотрудники милиции и военнослужащих.  Отчеканили.  Способствующее росту случаев дтп и бросили машину.  Тишков и оперуполномоченный 44 отдела милиции.  Нефтянки станут 20 крупнейших налогоплательщиков возросли на 25,4 тысячи штук на начало 2006 года в петербурге этой услугой в прошлый раз, видимо, отвернулись.  Гневную отповедь в адрес «злоумышленников».  Белуччи, катрин денев, мэл гибсон, ник перумов.  Перекрёстков не были акционированы по различным причинам.  Мучном переулке, передает рбк. \n",
            "\n",
            "Как сообщает ажур со ссылкой на пресс-службу угибдд петербурга и области, около 10 %.  7,89 рубля, что с 1 января за нарушение общественного порядка и безопасности администрации санкт-петербурга.  Урсуляк снимал не самостоятельную картину, фотографируя на память дорогие сердцу вещи, но не в счет погашения долга.  12-часовой – 3500 рублей, но и в другие.  Перинатального скрининга на наследственную и врожденную патологию; обеспечение прохладительными напитками при ожидании отправления рейса более 8 тысяч таких автомобилей.  Перезаключаемые договоры. \n",
            "\n",
            "По словам медиков, 10.  Неравномерность», - сказал путин.  Лобовом стекле кабины пилотов была обнаружена в ночь на 28 процентов, а оао \" интер \" создана в рамках которого современные исполнители доносят до нас не бывает.  Репродукция известной католической картины, подписанной «александр» и «жигули», - сказала она.  Цистерной воды.  Запрыгнет последний антитеррорист.  Скудным ассортиментом сидят группки мужчин «кавказской» внешности.  Стареем, необходимо ставить таблички: «согласны ли вы свои воспоминания? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e0a8dd5",
      "metadata": {
        "id": "8e0a8dd5"
      },
      "source": [
        "## Задание № 2 (2 балла)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f733858c",
      "metadata": {
        "id": "f733858c"
      },
      "source": [
        "Измените функцию generate_with_beam_search так, чтобы она работала с моделью, которая учитывает два предыдущих слова.\n",
        "Сравните получаемый результат с первым заданием.\n",
        "Также попробуйте начинать генерацию не с нуля (подавая \\<start> \\<start>), а с какого-то промпта. Но помните, что учитываться будут только два последних слова, так что не делайте длинные промпты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c426746a",
      "metadata": {
        "id": "c426746a"
      },
      "outputs": [],
      "source": [
        "class Beam:\n",
        "    def __init__(self, sequence, score):\n",
        "        self.sequence = sequence\n",
        "        self.score = score\n",
        "\n",
        "def generate_with_beam_search_trigram(trigram_matrix, id2word, word2id, bigram2id,\n",
        "                                      n=50, max_beams=5, prompt=None):\n",
        "\n",
        "    if prompt is None:\n",
        "        seq = ['<start>', '<start>']\n",
        "    else:\n",
        "        tokens = prompt.split()\n",
        "        tokens = ['<start>', '<start>'] + tokens\n",
        "        seq = tokens[-2:]  # последние два слова только\n",
        "\n",
        "    beams = [Beam(sequence=seq, score=0.0)]\n",
        "\n",
        "    for step in range(n):\n",
        "        new_beams = []\n",
        "        for beam in beams:\n",
        "            w1, w2 = beam.sequence[-2], beam.sequence[-1]\n",
        "            if w2 == '<end>':\n",
        "                new_beams.append(beam)\n",
        "                continue\n",
        "\n",
        "            bigram_id = bigram2id.get((w1, w2))\n",
        "\n",
        "            if bigram_id is None:\n",
        "                continue\n",
        "\n",
        "            probs = trigram_matrix[bigram_id].toarray()[0]\n",
        "            top_ids = probs.argsort()[:-(max_beams+1):-1]\n",
        "\n",
        "            for wid in top_ids:\n",
        "                p = probs[wid]\n",
        "                if p <= 0:\n",
        "                    continue\n",
        "\n",
        "                new_seq = beam.sequence + [id2word[wid]]\n",
        "                new_score = beam.score + np.log(p)\n",
        "\n",
        "                new_beams.append(Beam(new_seq, new_score))\n",
        "\n",
        "        beams = sorted(new_beams, key=lambda b: b.score, reverse=True)[:max_beams]\n",
        "\n",
        "        if all(b.sequence[-1] == '<end>' for b in beams):\n",
        "            break\n",
        "\n",
        "    best = sorted(beams, key=lambda b: b.score, reverse=True)\n",
        "    return [\" \".join(b.sequence) for b in best]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = generate_with_beam_search_trigram(\n",
        "    trigram_matrix=matrix,\n",
        "    id2word=id2word,\n",
        "    word2id=word2id,\n",
        "    bigram2id=bigram2id,\n",
        "    n=150,\n",
        "    max_beams=10\n",
        ")\n",
        "\n",
        "for r in results:\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQMuRTSiuNG0",
        "outputId": "4270346c-287d-473d-bcba-fa61b859a237"
      },
      "id": "aQMuRTSiuNG0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> <start> как передает корреспондент « фонтанки » . <end>\n",
            "<start> <start> как сообщили корреспонденту « фонтанки » . <end>\n",
            "<start> <start> как передает « газета . ru » . <end>\n",
            "<start> <start> как передает корреспондент « фонтанки » , - сказал он . <end>\n",
            "<start> <start> как передает корреспондент « фонтанки » в пресс-службе гу мчс рф по петербургу и ленобласти . <end>\n",
            "<start> <start> как передает « газета . ru » со ссылкой на пресс-службу гу мчс рф по петербургу и ленобласти . <end>\n",
            "<start> <start> как передает « газета . ru » со ссылкой на пресс-службу гу мчс рф по петербургу и ленинградской области , в том , что в петербурге . <end>\n",
            "<start> <start> как передает « газета . ru » со ссылкой на пресс-службу гу мчс рф по петербургу и ленинградской области , в том , что в ближайшее время . <end>\n",
            "<start> <start> как передает « газета . ru » со ссылкой на пресс-службу гу мчс рф по петербургу и ленинградской области , в том , что в случае , если бы не было . <end>\n",
            "<start> <start> как передает « газета . ru » со ссылкой на пресс-службу гу мчс рф по петербургу и ленинградской области , в том , что в случае , если бы не было , и в других регионах . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Без промпта и с бим-серч, результаты более детерминиированные и ориентируется только на один шаблон новостных текстов. Они все начинаются с ссылки на другой новостной источник."
      ],
      "metadata": {
        "id": "5X9Q9vZLvNIv"
      },
      "id": "5X9Q9vZLvNIv"
    },
    {
      "cell_type": "code",
      "source": [
        "results = generate_with_beam_search_trigram(\n",
        "    matrix, id2word, word2id, bigram2id,\n",
        "    n=150,\n",
        "    max_beams=10,\n",
        "    prompt=\"согласно сообщению\"\n",
        ")"
      ],
      "metadata": {
        "id": "eaX5zxXguSLE"
      },
      "id": "eaX5zxXguSLE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r in results:\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLgVwfebufRF",
        "outputId": "df65d09f-0adf-4c34-96fe-ffcb73dcf16b"
      },
      "id": "rLgVwfebufRF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "согласно сообщению пресс-службы обеих сторон . <end>\n",
            "согласно сообщению пресс-службы жилищного комитета юнис лукманов . <end>\n",
            "согласно сообщению пресс-службы кбдх дальнейший график закрытия будет корректироваться . <end>\n",
            "согласно сообщению пресс-службы жилищного комитета юниса лукманова . <end>\n",
            "согласно сообщению пресс-службы кбдх дальнейший график закрытия движения от стадиона « петровский » . <end>\n",
            "согласно сообщению пресс-службы кбдх дальнейший график закрытия движения от стадиона « петровский » в пресс-службе гу мчс рф по петербургу и ленобласти . <end>\n",
            "согласно сообщению пресс-службы кбдх дальнейший график закрытия движения от стадиона « петровский » в пресс-службе гу мчс рф по петербургу и ленинградской области , в том , что в петербурге . <end>\n",
            "согласно сообщению пресс-службы кбдх дальнейший график закрытия движения от стадиона « петровский » в пресс-службе гу мчс рф по петербургу и ленинградской области , в том , что в ближайшее время . <end>\n",
            "согласно сообщению пресс-службы кбдх дальнейший график закрытия движения от стадиона « петровский » в пресс-службе гу мчс рф по петербургу и ленинградской области , в том , что в случае , если бы не было . <end>\n",
            "согласно сообщению пресс-службы кбдх дальнейший график закрытия движения от стадиона « петровский » в пресс-службе гу мчс рф по петербургу и ленинградской области , в том , что в случае , если бы не было , и в других регионах . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = generate_with_beam_search_trigram(\n",
        "    matrix, id2word, word2id, bigram2id,\n",
        "    n=150,\n",
        "    max_beams=10,\n",
        "    prompt=\"в районе\"\n",
        ")\n",
        "for r in results:\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVvhY9T4v5Vl",
        "outputId": "49eb1b9b-0a85-44ee-bcdf-deee9a31c33d"
      },
      "id": "RVvhY9T4v5Vl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "в районе аварии затруднено . <end>\n",
            "в районе аварии образовалась огромная пробка . <end>\n",
            "в районе стадиона « петровский » . <end>\n",
            "в районе площади восстания . <end>\n",
            "в районе аварии образовалась пробка . <end>\n",
            "в районе станции метро « ладожская » . <end>\n",
            "в районе площади восстания ; фоторепортаж с думской улицы . <end>\n",
            "в районе площади восстания ; фоторепортаж с площади восстания . <end>\n",
            "в районе площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с думской улицы . <end>\n",
            "в районе площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с площади восстания ; фоторепортаж с\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = generate_with_beam_search_trigram(\n",
        "    matrix, id2word, word2id, bigram2id,\n",
        "    n=150,\n",
        "    max_beams=10,\n",
        "    prompt=\"по предварительным данным\"\n",
        ")\n",
        "for r in results:\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhVQ1Kk7wCO2",
        "outputId": "69cdb968-33a9-411d-b17f-889eb5740328"
      },
      "id": "fhVQ1Kk7wCO2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "предварительным данным , причиной аварии стало заложенное на путях . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на путях пожарной эвакуации . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на путях самодельное взрывное устройство . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на рельсах лежит человек . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на путях самодельное взрывное устройство мощностью около двух килограммов тротила . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на путях самодельное взрывное устройство мощностью около двух часов . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на путях самодельное взрывное устройство мощностью около двух часов дня . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на путях самодельное взрывное устройство мощностью около двух лет . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на путях самодельное взрывное устройство , состоящее из будильника , пальчиковых батареек и картонной коробки из-под охотничьих спичек с прикрепленными к ней самые теплые чувства , воплощённые на сцене . <end>\n",
            "предварительным данным , причиной аварии стало заложенное на путях самодельное взрывное устройство , состоящее из будильника , пальчиковых батареек и картонной коробки из-под охотничьих спичек с прикрепленными к ней самые теплые чувства , воплощённые на сцене театра « бенефис » , - сказал он . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = generate_with_beam_search_trigram(\n",
        "    matrix, id2word, word2id, bigram2id,\n",
        "    n=150,\n",
        "    max_beams=10,\n",
        "    prompt=\"они заявили\"\n",
        ")\n",
        "for r in results:\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0zAxxcxw5tV",
        "outputId": "1036f69d-b22f-407d-8284-06c81f61929c"
      },
      "id": "n0zAxxcxw5tV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "они заявили на пресс-конференции в москве . <end>\n",
            "они заявили на сегодняшнем заседании городского правительства . <end>\n",
            "они заявили на сегодняшнем заседании городского парламента . <end>\n",
            "они заявили на пресс-конференции в москве и петербурге . <end>\n",
            "они заявили на сегодняшнем заседании городского штаба по благоустройству и дорожному хозяйству . <end>\n",
            "они заявили на сегодняшнем заседании городского правительства губернатор валентина матвиенко . <end>\n",
            "они заявили на сегодняшнем заседании городского правительства губернатор петербурга валентина матвиенко . <end>\n",
            "они заявили на сегодняшнем заседании городского штаба по благоустройству и дорожному хозяйству , градостроительству и архитектуре . <end>\n",
            "они заявили на сегодняшнем заседании городского штаба по благоустройству и дорожному хозяйству , градостроительству и архитектуре ( кга ) александр брод . <end>\n",
            "они заявили на сегодняшнем заседании городского штаба по благоустройству и дорожному хозяйству , градостроительству и архитектуре ( кга ) александр брод , наибольшее количество голосов , у нас есть опоры разного рода , тогда как в случае , если бы не было . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проблема генераций, что точка как будто имеет довольно большую вероятность. Но одновременно отказываться от знаков препинания – грустно, потому что у нас в текстах появляются очень нечеловеческие тексты."
      ],
      "metadata": {
        "id": "Gz2O4013xBmg"
      },
      "id": "Gz2O4013xBmg"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}