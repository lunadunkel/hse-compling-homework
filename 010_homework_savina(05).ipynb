{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c422aa0",
      "metadata": {
        "id": "9c422aa0"
      },
      "source": [
        "# Задание 1 (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4a72790",
      "metadata": {
        "id": "e4a72790"
      },
      "source": [
        "Обучите word2vec модели с негативным семплированием (cbow и skip-gram) аналогично тому, как это было сделано в семинаре. Вам нужно изменить следующие пункты:\n",
        "1) добавьте лемматизацию в предобработку (любым способом)  \n",
        "2) измените размер окна в большую или меньшую сторону\n",
        "3) измените размерность итоговых векторов\n",
        "\n",
        "Выберете несколько не похожих по смыслу слов (не таких как в семинаре), и протестируйте полученные эмбединги (найдите ближайшие слова и оцените качество, как в семинаре).\n",
        "Постарайтесь обучать модели как можно дольше и на как можно большем количестве данных. (Но если у вас мало времени или ресурсов, то допустимо взять поменьше данных и поставить меньше эпох)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### все install'ы"
      ],
      "metadata": {
        "id": "5YRy6Hn7uEy-"
      },
      "id": "5YRy6Hn7uEy-"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymystem3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvo6rhifGJv6",
        "outputId": "2c5b68ae-ef13-4754-86c5-34ca3e03709e"
      },
      "id": "Rvo6rhifGJv6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymystem3\n",
            "  Downloading pymystem3-0.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pymystem3) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pymystem3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pymystem3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pymystem3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pymystem3) (2025.11.12)\n",
            "Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pymystem3\n",
            "Successfully installed pymystem3-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/refs/heads/master/notebooks/word_embeddings/wiki_data.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mDbA7t3GLpR",
        "outputId": "e4ec101a-8fe7-4872-d74f-e10d5c9ee873"
      },
      "id": "3mDbA7t3GLpR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-27 13:56:32--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/refs/heads/master/notebooks/word_embeddings/wiki_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68582461 (65M) [text/plain]\n",
            "Saving to: ‘wiki_data.txt’\n",
            "\n",
            "wiki_data.txt       100%[===================>]  65.41M   209MB/s    in 0.3s    \n",
            "\n",
            "2025-12-27 13:56:34 (209 MB/s) - ‘wiki_data.txt’ saved [68582461/68582461]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "# import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from pymystem3 import Mystem\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "# import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.metrics.pairwise import cosine_distances"
      ],
      "metadata": {
        "id": "edXNPxuSuLU9"
      },
      "id": "edXNPxuSuLU9",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MyStem = Mystem(disambiguation=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Zxho6rNguaHo"
      },
      "id": "Zxho6rNguaHo",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki = open('wiki_data.txt').read().split('\\n')"
      ],
      "metadata": {
        "id": "2MvginvDtpTV"
      },
      "id": "2MvginvDtpTV",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### предобработка"
      ],
      "metadata": {
        "id": "2ljd8bKtvDCv"
      },
      "id": "2ljd8bKtvDCv"
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_sent(sent):\n",
        "    res = MyStem.analyze(sent)\n",
        "    lemma = []\n",
        "    for analysis in res:\n",
        "        lex = ''\n",
        "        if 'analysis' in analysis and analysis['analysis']:\n",
        "            lex = analysis['analysis'][0].get('lex', '')\n",
        "        if lex: lemma.append(lex)\n",
        "    return lemma\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = re.sub('#+', ' ', text.lower()).split()\n",
        "    tokens = [token.strip(punctuation) for token in tokens]\n",
        "    tokens = lemmatize_sent(' '.join(tokens))\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "_DmHQW0UvF_2"
      },
      "id": "_DmHQW0UvF_2",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wiki[0])\n",
        "print(preprocess(wiki[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTiJD1pPujH9",
        "outputId": "3a17227f-61fb-43b7-a7f3-95233990dd5a"
      },
      "id": "qTiJD1pPujH9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######Новостройка (Нижегородская область)############Новостро́йка — сельский посёлок в Дивеевском районе Нижегородской области. Входит в состав Сатисского сельсовета.############Посёлок расположен в 12,5 км к югу от села Дивеева и 1 км к западу от города Сарова, на правом берегу реки Вичкинза (правый приток реки Сатис). Окружён смешанными лесами. Соединён асфальтовой дорогой с посёлком Цыгановка (1,5 км) и грунтовыми просёлочными дорогами с посёлком Сатис (3,5 км). Название Новостройка является сугубо официальным, местное население использует исключительно альтернативное название — Хитрый. Употребляется языковой оборот «…на Хитром». Ранее используемые названия — Песчаный, Известковый.############Основан в 1920-х годах переселенцами из соседних сёл Аламасово и Нарышкино (расположенных соответственно в 8 и 14 км к западу в Вознесенском районе).############Традиционно в посёлке жили рабочие совхоза «Вперёд» (центр в посёлке Сатис). Возле посёлка расположен карьер где активно добывали доломитовую муку и бутовый камень (в настоящее время официально закрыт).############По данным 1978 года посёлок Новостройка характеризовался как неперспективный, здесь насчитывалось 24 хозяйства и 43 жителя. Водоснабжение осуществлялось из колодцев и родников, учреждения соцкультбыта отсутствовали. В 1992 году в посёлке насчитывалось 7 хозяйств и 16 жителей, из которых 7 трудоспособного возраста. На 1 января 1995 года в посёлке имелось 6 хозяйств и 12 жителей.############В настоящее время посёлок не только остаётся жилым, но и получил развитие благодаря своей близости к святым источникам. В полукилометре расположен Казанский родник, а в 1,2 км — источник святого Серафима Саровского.############В посёлке расположен скит Дивеевского монастыря.######В 2012 году был освящён домовой храм в честь Серафима Саровского.##############################\n",
            "['новостройка', 'нижегородский', 'область', 'новостройка', 'сельский', 'поселок', 'в', 'дивеевский', 'район', 'нижегородский', 'область', 'входить', 'в', 'состав', 'сатисский', 'сельсовет', 'поселок', 'располагать', 'в', 'км', 'к', 'юг', 'от', 'садиться', 'дивеево', 'и', 'км', 'к', 'запад', 'от', 'город', 'саров', 'на', 'правый', 'берег', 'река', 'вичкинза', 'правый', 'приток', 'река', 'сатиса', 'окружать', 'смешанный', 'лес', 'соединять', 'асфальтовый', 'дорогой', 'с', 'поселок', 'цыгановка', 'км', 'и', 'грунтовый', 'проселочный', 'дорога', 'с', 'поселок', 'сатиса', 'км', 'название', 'новостройка', 'являться', 'сугубо', 'официальный', 'местный', 'население', 'использовать', 'исключительно', 'альтернативный', 'название', 'хитрый', 'употребляться', 'языковой', 'оборот', 'на', 'хитрый', 'ранее', 'использовать', 'название', 'песчаный', 'известковый', 'основывать', 'в', 'х', 'год', 'переселенец', 'из', 'соседний', 'село', 'аламасово', 'и', 'нарышкино', 'располагать', 'соответственно', 'в', 'и', 'км', 'к', 'запад', 'в', 'вознесенский', 'район', 'традиционно', 'в', 'поселок', 'жить', 'рабочий', 'совхоз', 'вперед', 'центр', 'в', 'поселок', 'сатиса', 'возле', 'поселок', 'располагать', 'карьер', 'где', 'активно', 'добывать', 'доломитовый', 'мука', 'и', 'бутовый', 'камень', 'в', 'настоящий', 'время', 'официально', 'закрывать', 'по', 'данные', 'год', 'поселок', 'новостройка', 'характеризоваться', 'как', 'неперспективный', 'здесь', 'насчитываться', 'хозяйство', 'и', 'житель', 'водоснабжение', 'осуществляться', 'из', 'колодец', 'и', 'родник', 'учреждение', 'соцкультбыт', 'отсутствовать', 'в', 'год', 'в', 'поселок', 'насчитываться', 'хозяйство', 'и', 'житель', 'из', 'который', 'трудоспособный', 'возраст', 'на', 'январь', 'год', 'в', 'поселок', 'иметься', 'хозяйство', 'и', 'житель', 'в', 'настоящий', 'время', 'поселок', 'не', 'только', 'оставаться', 'жилой', 'но', 'и', 'получать', 'развитие', 'благодаря', 'свой', 'близость', 'к', 'святой', 'источник', 'в', 'полкилометра', 'располагать', 'казанский', 'родник', 'а', 'в', 'км', 'источник', 'святой', 'серафим', 'саровский', 'в', 'поселок', 'располагать', 'скит', 'дивеевский', 'монастырь', 'в', 'год', 'быть', 'освящать', 'домовый', 'храм', 'в', 'честь', 'серафим', 'саровский']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предобработка всех данных\n",
        "wiki_preprocessed = []\n",
        "for sent in tqdm(wiki):\n",
        "    processed = preprocess(sent)\n",
        "    if processed:\n",
        "        wiki_preprocessed.append(processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-BsOSdc6ilS",
        "outputId": "5b305f2f-c662-46f5-9215-25d133c5cb2f"
      },
      "id": "b-BsOSdc6ilS",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20003/20003 [04:10<00:00, 79.94it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = Counter()\n",
        "for sent in wiki_preprocessed:\n",
        "    word_counts.update(sent)\n",
        "\n",
        "min_count = 10\n",
        "vocab = [word for word, count in word_counts.items() if count >= min_count]\n",
        "\n",
        "word2id = {'PAD': 0}\n",
        "for idx, word in enumerate(vocab, 1):\n",
        "    word2id[word] = idx\n",
        "id2word = {idx: word for word, idx in word2id.items()}\n",
        "\n",
        "print(f\"Размер словаря: {len(vocab)}\")\n",
        "print(f\"Примеры слов: {vocab[:20]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2CNAGvY6qmw",
        "outputId": "807a0f4e-4ad5-4719-895a-02abaace883d"
      },
      "id": "h2CNAGvY6qmw",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря: 25849\n",
            "Примеры слов: ['новостройка', 'нижегородский', 'область', 'сельский', 'поселок', 'в', 'дивеевский', 'район', 'входить', 'состав', 'сатисский', 'сельсовет', 'располагать', 'км', 'к', 'юг', 'от', 'садиться', 'дивеево', 'и']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "\n",
        "for text in tqdm(wiki):\n",
        "    tokens = preprocess(text)\n",
        "    if not tokens:\n",
        "        continue\n",
        "    ids = [word2id[token] for token in tokens if token in word2id]\n",
        "    sentences.append(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNeaKWc52B72",
        "outputId": "0a5dc4e0-90c7-407e-8881-db790668d6e4"
      },
      "id": "kNeaKWc52B72",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20003/20003 [04:12<00:00, 79.29it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### модели"
      ],
      "metadata": {
        "id": "2ZC-6CyuF4cn"
      },
      "id": "2ZC-6CyuF4cn"
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOWNegSampling(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, window_size):\n",
        "        super().__init__()\n",
        "        self.target_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.context_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def forward(self, target_ids, context_ids):\n",
        "        \"\"\"\n",
        "        target_ids: (batch,)\n",
        "        context_ids: (batch, window_size)\n",
        "        \"\"\"\n",
        "        t = self.target_emb(target_ids)          # (batch, emb_dim)\n",
        "        c = self.context_emb(context_ids)        # (batch, window, emb_dim)\n",
        "        c_sum = c.sum(dim=1)                     # (batch, emb_dim)\n",
        "        dot = (t * c_sum).sum(dim=1)             # (batch,)\n",
        "        return dot\n",
        "\n",
        "class SkipGramNegSampling(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, window_size):\n",
        "        super().__init__()\n",
        "        self.center_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.context_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def forward(self, center_ids, context_ids):\n",
        "        \"\"\"\n",
        "        center_ids: (batch,)\n",
        "        context_ids: (batch,)\n",
        "        \"\"\"\n",
        "        center = self.center_emb(center_ids)      # (batch, emb_dim)\n",
        "        context = self.context_emb(context_ids)   # (batch, emb_dim)\n",
        "        dot = (center * context).sum(dim=1)       # (batch,)\n",
        "        return dot"
      ],
      "metadata": {
        "id": "PuTJnLvjAuiM"
      },
      "id": "PuTJnLvjAuiM",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sequences, maxlen, padding='post', value=0):\n",
        "    \"\"\"\n",
        "    sequences: list of lists (разной длины)\n",
        "    возвращает np.array shape (len(sequences), maxlen)\n",
        "    \"\"\"\n",
        "    res = np.full((len(sequences), maxlen), value, dtype='int64')\n",
        "    for i, seq in enumerate(sequences):\n",
        "        if not seq:\n",
        "            continue\n",
        "        if len(seq) >= maxlen:\n",
        "            if padding == 'post':\n",
        "                res[i] = np.array(seq[:maxlen])\n",
        "            else:\n",
        "                res[i] = np.array(seq[-maxlen:])\n",
        "        else:\n",
        "            if padding == 'post':\n",
        "                res[i, :len(seq)] = np.array(seq)\n",
        "            else:\n",
        "                res[i, -len(seq):] = np.array(seq)\n",
        "    return res"
      ],
      "metadata": {
        "id": "ZtpN21awIpnh"
      },
      "id": "ZtpN21awIpnh",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_batches_skipgram(sentences, window=5, batch_size=1000):\n",
        "    left_context_length = (window/2).__ceil__()\n",
        "    right_context_length = window // 2\n",
        "\n",
        "    while True:\n",
        "        X_center = []\n",
        "        X_context = []\n",
        "        y = []\n",
        "\n",
        "        for sent in sentences:\n",
        "            for i in range(len(sent)-1):\n",
        "                center_word = sent[i]\n",
        "                context_words = sent[max(0, i-left_context_length):i] + sent[i+1:i+right_context_length+1]\n",
        "\n",
        "                for context_word in context_words:\n",
        "                    X_center.append(center_word)\n",
        "                    X_context.append(context_word)\n",
        "                    y.append(1)\n",
        "\n",
        "                    X_center.append(center_word)\n",
        "                    X_context.append(np.random.randint(vocab_size))\n",
        "                    y.append(0)\n",
        "\n",
        "                if len(X_center) >= batch_size:\n",
        "                    X_center_arr = np.array(X_center[:batch_size], dtype='int64')\n",
        "                    X_context_arr = np.array(X_context[:batch_size], dtype='int64')\n",
        "                    y_arr = np.array(y[:batch_size], dtype='float32')\n",
        "                    yield (X_center_arr, X_context_arr), y_arr\n",
        "                    X_center = X_center[batch_size:]\n",
        "                    X_context = X_context[batch_size:]\n",
        "                    y = y[batch_size:]"
      ],
      "metadata": {
        "id": "oxL2hiIAJVnn"
      },
      "id": "oxL2hiIAJVnn",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_batches_cbow(sentences, window=5, batch_size=1000):\n",
        "    left_context_length = (window/2).__ceil__()\n",
        "    right_context_length = window // 2\n",
        "\n",
        "    while True:\n",
        "        X_target = []\n",
        "        X_context = []\n",
        "        y = []\n",
        "\n",
        "        for sent in sentences:\n",
        "            for i in range(len(sent)-1):\n",
        "                word = sent[i]\n",
        "                context = sent[max(0, i-left_context_length):i] + sent[i+1:i+right_context_length]\n",
        "\n",
        "                X_target.append(word)\n",
        "                X_context.append(context)\n",
        "                y.append(1)\n",
        "\n",
        "                X_target.append(np.random.randint(vocab_size))\n",
        "                X_context.append(context)\n",
        "                y.append(0)\n",
        "\n",
        "                if len(X_target) >= batch_size:\n",
        "                    X_target_arr = np.array(X_target, dtype='int64')\n",
        "                    X_context_arr = pad_sequences(X_context, maxlen=window, padding='post', value=0)\n",
        "                    y_arr = np.array(y, dtype='float32')\n",
        "                    yield (X_target_arr, X_context_arr), y_arr\n",
        "                    X_target, X_context, y = [], [], []"
      ],
      "metadata": {
        "id": "XYSkymisIXko"
      },
      "id": "XYSkymisIXko",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2id)\n",
        "emb_dim = 200\n",
        "window_size = 7\n",
        "num_epochs = 15\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "_OGlSzaEBElC"
      },
      "id": "_OGlSzaEBElC",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CBOW\n",
        "cbow_model = CBOWNegSampling(vocab_size, emb_dim, window_size).to(device)\n",
        "optimizer_cbow = torch.optim.Adam(cbow_model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "FfpFQl0ZBJoO"
      },
      "id": "FfpFQl0ZBJoO",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = 5000\n",
        "validation_steps = 30\n",
        "num_epochs = 10\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "train_gen = gen_batches_cbow(sentences[:19000], window=window_size, batch_size=1000)\n",
        "valid_gen = gen_batches_cbow(sentences[19000:], window=window_size, batch_size=1000)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    cbow_model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for step in tqdm(range(steps_per_epoch)):\n",
        "        (X_t, X_c), y = next(train_gen)\n",
        "        X_t = torch.LongTensor(X_t).to(device)\n",
        "        X_c = torch.LongTensor(X_c).to(device)\n",
        "        y_t = torch.FloatTensor(y).to(device)\n",
        "\n",
        "        optimizer_cbow.zero_grad()\n",
        "        logits = cbow_model(X_t, X_c)\n",
        "        loss = criterion(logits, y_t)\n",
        "        loss.backward()\n",
        "        optimizer_cbow.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "    epoch_loss /= steps_per_epoch\n",
        "\n",
        "    # validation\n",
        "    cbow_model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for _ in range(validation_steps):\n",
        "            (X_t, X_c), y = next(valid_gen)\n",
        "            X_t = torch.LongTensor(X_t).to(device)\n",
        "            X_c = torch.LongTensor(X_c).to(device)\n",
        "            y_t = torch.FloatTensor(y).to(device)\n",
        "\n",
        "            logits = cbow_model(X_t, X_c)\n",
        "            loss = criterion(logits, y_t)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= validation_steps\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - train loss: {epoch_loss:.4f}, val loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw41c0jCI7E9",
        "outputId": "202013d7-0112-4987-d0a6-a593a8836e23"
      },
      "id": "Nw41c0jCI7E9",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:42<00:00, 117.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - train loss: 0.7342, val loss: 2.0102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:41<00:00, 120.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 - train loss: 0.7099, val loss: 2.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:39<00:00, 125.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 - train loss: 0.5915, val loss: 2.2715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:39<00:00, 125.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 - train loss: 0.5155, val loss: 1.9326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:40<00:00, 123.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 - train loss: 0.4813, val loss: 2.1972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:39<00:00, 125.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 - train loss: 0.3923, val loss: 2.2256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:39<00:00, 125.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 - train loss: 0.3812, val loss: 2.0822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:40<00:00, 124.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 - train loss: 0.3317, val loss: 2.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:40<00:00, 124.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 - train loss: 0.3013, val loss: 2.3357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:39<00:00, 125.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 - train loss: 0.2871, val loss: 1.9685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = cbow_model.context_emb.weight.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "HXRx1-CfRrt3"
      },
      "id": "HXRx1-CfRrt3",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHctd4GhSI28",
        "outputId": "024a38d8-7462-496f-983b-4d4713799046"
      },
      "id": "RHctd4GhSI28",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25850, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar(word, embeddings):\n",
        "    similar = [id2word[i] for i in\n",
        "               cosine_distances(embeddings[word2id[word]].reshape(1, -1), embeddings).argsort()[0][:10]]\n",
        "    return similar"
      ],
      "metadata": {
        "id": "ZTZMJEicR50L"
      },
      "id": "ZTZMJEicR50L",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['философия', 'болезнь', 'музыка', 'машина']"
      ],
      "metadata": {
        "id": "qjMjm61zSWJM"
      },
      "id": "qjMjm61zSWJM",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(f'Слово: {word}\\n\\t{most_similar(word, embeddings)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8yma2iuR6ux",
        "outputId": "286556e7-3e1e-42c3-fab9-9a90c9a75dfe"
      },
      "id": "V8yma2iuR6ux",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слово: философия\n",
            "\t['философия', 'артур', 'религия', 'имеретинский', 'колесница', 'порождать', 'жак', 'ислам', 'рач', 'асановский']\n",
            "Слово: болезнь\n",
            "\t['болезнь', 'заболевание', 'случай', 'выбывать', 'профессия', 'кен', 'препарат', 'экономичный', 'нищета', 'сестринский']\n",
            "Слово: музыка\n",
            "\t['музыка', 'песня', 'сочинение', 'композитор', 'театральный', 'правота', 'тенор', 'концерт', 'театр', 'вибрация']\n",
            "Слово: машина\n",
            "\t['машина', 'труднодоступный', 'размещение', 'увеличивать', 'надежность', 'колесо', 'курок', 'упорно', 'товар', 'мантия']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кажется, что что-то обучилось даже:\n",
        "- для философии: встречается религия, \"артур\" – мб Шопенгауэр, \"жак\" – Жан-Жак Руссо?\n",
        "- для болезни: заболевание, нищета\n",
        "- для музыки: песня, сочинение, композитор, тенор, концерт, театр, вибрации – все подходит\n",
        "- для машины: если колесо... надежность и товар тоже осмысленно\n"
      ],
      "metadata": {
        "id": "GS61fVi8TV--"
      },
      "id": "GS61fVi8TV--"
    },
    {
      "cell_type": "code",
      "source": [
        "# SkipGram\n",
        "skip_model = SkipGramNegSampling(vocab_size, emb_dim, window_size).to(device)\n",
        "optimizer_skip = torch.optim.Adam(skip_model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "f1xQMoP6UKLV"
      },
      "id": "f1xQMoP6UKLV",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = 5000\n",
        "validation_steps = 30\n",
        "num_epochs = 20\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "train_gen = gen_batches_skipgram(sentences[:19000], window=window_size, batch_size=1000)\n",
        "valid_gen = gen_batches_skipgram(sentences[19000:], window=window_size, batch_size=1000)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    skip_model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for step in tqdm(range(steps_per_epoch)):\n",
        "        (X_t, X_c), y = next(train_gen)\n",
        "        X_t = torch.LongTensor(X_t).to(device)\n",
        "        X_c = torch.LongTensor(X_c).to(device)\n",
        "        y_t = torch.FloatTensor(y).to(device)\n",
        "\n",
        "        optimizer_skip.zero_grad()\n",
        "        logits = skip_model(X_t, X_c)\n",
        "        loss = criterion(logits, y_t)\n",
        "        loss.backward()\n",
        "        optimizer_skip.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "    epoch_loss /= steps_per_epoch\n",
        "\n",
        "    # validation\n",
        "    skip_model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for _ in range(validation_steps):\n",
        "            (X_t, X_c), y = next(valid_gen)\n",
        "            X_t = torch.LongTensor(X_t).to(device)\n",
        "            X_c = torch.LongTensor(X_c).to(device)\n",
        "            y_t = torch.FloatTensor(y).to(device)\n",
        "\n",
        "            logits = skip_model(X_t, X_c)\n",
        "            loss = criterion(logits, y_t)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= validation_steps\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - train loss: {epoch_loss:.4f}, val loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "AA-o00m7UYuG",
        "outputId": "89c1a935-f164-4da2-dc50-d21d1bbd4303"
      },
      "id": "AA-o00m7UYuG",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 164.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - train loss: 0.8883, val loss: 0.8414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:31<00:00, 159.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 - train loss: 0.8357, val loss: 0.8929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 164.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 - train loss: 0.7948, val loss: 0.8558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 162.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20 - train loss: 0.7493, val loss: 0.8615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 164.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20 - train loss: 0.7161, val loss: 0.7168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 162.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20 - train loss: 0.6969, val loss: 0.7164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 165.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 - train loss: 0.6680, val loss: 0.7254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:31<00:00, 158.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 - train loss: 0.6524, val loss: 0.7128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 162.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 - train loss: 0.6175, val loss: 0.7219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 162.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 - train loss: 0.6108, val loss: 0.7159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:30<00:00, 164.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 - train loss: 0.6722, val loss: 0.6163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:33<00:00, 147.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 - train loss: 0.6107, val loss: 0.6584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 138/5000 [00:00<00:29, 167.44it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2584053293.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mX_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-626851403.py\u001b[0m in \u001b[0;36mgen_batches_skipgram\u001b[0;34m(sentences, window, batch_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;31m# Негативный пример (то же центральное слово, случайный контекст)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mX_center\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0mX_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(обучила сначала на 10, потом еще на 10)"
      ],
      "metadata": {
        "id": "_koQDkCgXZt1"
      },
      "id": "_koQDkCgXZt1"
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = skip_model.context_emb.weight.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "UjmmNhznV2Ir"
      },
      "id": "UjmmNhznV2Ir",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(f'Слово: {word}\\n\\t{most_similar(word, embeddings)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In2TDw-lV5xe",
        "outputId": "197c5bee-8c38-4073-9c9a-7935ed6c3b28"
      },
      "id": "In2TDw-lV5xe",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слово: философия\n",
            "\t['философия', 'останки', 'медико', 'смешать', 'заведующий', 'бородкин', 'рацион', 'мао', 'следствие', 'оперный']\n",
            "Слово: болезнь\n",
            "\t['болезнь', 'возможность', 'много', 'лист', 'использовать', 'со', 'из-за', 'второй', 'мочь', 'вода']\n",
            "Слово: музыка\n",
            "\t['музыка', 'не', 'о', 'многий', 'работа', 'он', 'так', 'это', 'она', 'известный']\n",
            "Слово: машина\n",
            "\t['машина', 'или', 'мочь', 'это', 'за', 'название', 'часть', 'иметь', 'однако', 'весь']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Со skipgram совсем все как-то неблизко вышло."
      ],
      "metadata": {
        "id": "Fkq9x64QXtxu"
      },
      "id": "Fkq9x64QXtxu"
    },
    {
      "cell_type": "markdown",
      "id": "c3b61b7c",
      "metadata": {
        "id": "c3b61b7c"
      },
      "source": [
        "# Задание 2 (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66eff080",
      "metadata": {
        "id": "66eff080"
      },
      "source": [
        "Обучите 1 word2vec и 1 fastext модель в gensim. В каждой из модели нужно задать все параметры, которые мы разбирали на семинаре. Заданные значения должны отличаться от дефолтных и от тех, что мы использовали на семинаре."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKWRO87WX9L4",
        "outputId": "06edec36-b789-4a49-bff5-54c4572e3e5b"
      },
      "id": "hKWRO87WX9L4",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "s-R1H-D1X6Gf"
      },
      "id": "s-R1H-D1X6Gf",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "986c2018",
      "metadata": {
        "id": "986c2018"
      },
      "outputs": [],
      "source": [
        "w2v = gensim.models.Word2Vec(\n",
        "    wiki_preprocessed,\n",
        "    vector_size=200,\n",
        "    min_count=15,\n",
        "    max_vocab_size=15000,\n",
        "    window=8,\n",
        "    epochs=15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(f'Слово: {word}\\n\\t{w2v.wv.most_similar(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggf_l58gZDrD",
        "outputId": "6e8d804c-1ca5-43bf-c392-5debef5468ff"
      },
      "id": "ggf_l58gZDrD",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слово: философия\n",
            "\t[('социология', 0.6720197200775146), ('философский', 0.6267057061195374), ('математика', 0.621552586555481), ('литература', 0.6027094125747681), ('психология', 0.5849205851554871), ('лекция', 0.5761131644248962), ('религия', 0.5697950124740601), ('астрономия', 0.5573999881744385), ('докторский', 0.5480669736862183), ('монография', 0.5442533493041992)]\n",
            "Слово: болезнь\n",
            "\t[('заболевание', 0.6812194585800171), ('туберкулез', 0.6477969288825989), ('лечение', 0.5960898995399475), ('приступ', 0.5943763256072998), ('страдать', 0.5897641777992249), ('сердечный', 0.5820220708847046), ('больной', 0.5781915187835693), ('боль', 0.5705823302268982), ('синдром', 0.5704296231269836), ('рак', 0.5518892407417297)]\n",
            "Слово: музыка\n",
            "\t[('пение', 0.6459359526634216), ('композитор', 0.6363242268562317), ('музыкальный', 0.6213828325271606), ('фортепиано', 0.6014958024024963), ('мелодия', 0.5994106531143188), ('репертуар', 0.5950559973716736), ('джаз', 0.5773571133613586), ('композиция', 0.5731637477874756), ('вокальный', 0.566504180431366), ('джазовый', 0.5607585310935974)]\n",
            "Слово: машина\n",
            "\t[('грузовик', 0.6554883718490601), ('автомобиль', 0.6361408829689026), ('двигатель', 0.5939822793006897), ('шасси', 0.5835054516792297), ('водитель', 0.5711334347724915), ('руль', 0.5492171049118042), ('фюзеляж', 0.5385827422142029), ('кабина', 0.5332172513008118), ('кузов', 0.5322853326797485), ('мотоцикл', 0.5175518989562988)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft = gensim.models.FastText(\n",
        "    wiki_preprocessed,\n",
        "    vector_size=250,\n",
        "    min_count=12,\n",
        "    window=4,\n",
        "    epochs=7,\n",
        "    min_n=4,\n",
        "    max_n=8\n",
        ")"
      ],
      "metadata": {
        "id": "4TPxOqr6ZWlu"
      },
      "id": "4TPxOqr6ZWlu",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(f'Слово: {word}\\n\\t{ft.wv.most_similar(word)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWg6Twk3ZrM_",
        "outputId": "ca33451c-6ab5-4708-a2c8-9bbf34cc3128"
      },
      "id": "uWg6Twk3ZrM_",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слово: философия\n",
            "\t[('философ', 0.958625316619873), ('филология', 0.8999954462051392), ('математика', 0.8433587551116943), ('политология', 0.8416385054588318), ('теология', 0.8344107866287231), ('социология', 0.8315575122833252), ('антология', 0.830829918384552), ('психология', 0.8301852345466614), ('софия', 0.8184142708778381), ('поэтика', 0.814580500125885)]\n",
            "Слово: болезнь\n",
            "\t[('заболевание', 0.7950320243835449), ('заболеть', 0.7804254293441772), ('туберкулез', 0.7330014705657959), ('болейн', 0.6807439923286438), ('рак', 0.6555722951889038), ('боль', 0.6554720997810364), ('здоровье', 0.6397715210914612), ('болеть', 0.6372828483581543), ('симптом', 0.6367868781089783), ('заболевать', 0.6295412182807922)]\n",
            "Слово: музыка\n",
            "\t[('поп-музыка', 0.9790514707565308), ('рок-музыка', 0.9784204363822937), ('музыкально', 0.9102877974510193), ('музыковед', 0.890175461769104), ('музыкант', 0.8644749522209167), ('мелодия', 0.7982892394065857), ('муза', 0.7873231172561646), ('джаз', 0.7746879458427429), ('композитор', 0.7743276953697205), ('хор', 0.748645544052124)]\n",
            "Слово: машина\n",
            "\t[('автомашина', 0.8945332169532776), ('ашина', 0.8629522919654846), ('машинка', 0.8295745849609375), ('бронемашина', 0.8290285468101501), ('кабриолет', 0.8040897250175476), ('гидромашина', 0.7897406220436096), ('мотор', 0.7742208242416382), ('бронеавтомобиль', 0.7645062804222107), ('двигатель', 0.7547557353973389), ('мотовоз', 0.7500430941581726)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4bb928c",
      "metadata": {
        "id": "e4bb928c"
      },
      "source": [
        "# Задание 3 (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3019b0d1",
      "metadata": {
        "id": "3019b0d1"
      },
      "source": [
        "Используя датасет для классификации (labeled.csv), обучите классификатор на базе эмбеддингов. Оцените качество на отложенной выборке.   \n",
        "В качестве эмбеддинг модели вы можете использовать одну из моделей обученных в предыдущем задании или использовать одну из предобученных моделей с rusvectores (удостоверьтесь что правильно воспроизводите предобработку в этом случае!)  \n",
        "Для того, чтобы построить эмбединг целого текста, усредните вектора отдельных слов в один общий вектор.\n",
        "В качестве алгоритма классификации используйте LogisicticRegression (можете попробовать SGDClassifier, чтобы было побыстрее)  \n",
        "F1 мера должна быть выше 20%."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/mannefedov/compling_nlp_hse_course/raw/refs/heads/master/notebooks/word_embeddings/labeled.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLoE4ALcezIy",
        "outputId": "355666ba-0407-4ec3-f66d-7a0e2633412b"
      },
      "id": "oLoE4ALcezIy",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-27 15:44:09--  https://github.com/mannefedov/compling_nlp_hse_course/raw/refs/heads/master/notebooks/word_embeddings/labeled.csv\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/refs/heads/master/notebooks/word_embeddings/labeled.csv [following]\n",
            "--2025-12-27 15:44:10--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/refs/heads/master/notebooks/word_embeddings/labeled.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4669913 (4.5M) [application/octet-stream]\n",
            "Saving to: ‘labeled.csv’\n",
            "\n",
            "labeled.csv         100%[===================>]   4.45M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-12-27 15:44:11 (108 MB/s) - ‘labeled.csv’ saved [4669913/4669913]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "ed908832",
      "metadata": {
        "id": "ed908832"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('labeled.csv')"
      ],
      "metadata": {
        "id": "gc3vBWBOfB7Z"
      },
      "id": "gc3vBWBOfB7Z",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "scMIlguvfCaI",
        "outputId": "861a0810-9fa9-4237-8299-1df6e1d71c2c"
      },
      "id": "scMIlguvfCaI",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 comment  toxic\n",
              "0                   Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
              "1      Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
              "2                              Собаке - собачья смерть\\n    1.0\n",
              "3      Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
              "4      тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n",
              "...                                                  ...    ...\n",
              "14407  Вонючий совковый скот прибежал и ноет. А вот и...    1.0\n",
              "14408  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0\n",
              "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0\n",
              "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0\n",
              "14411  До сих пор пересматриваю его видео. Орамбо кст...    0.0\n",
              "\n",
              "[14412 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81efe7f8-cba1-495e-a7f9-c0ae06031a88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14407</th>\n",
              "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14408</th>\n",
              "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14409</th>\n",
              "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14410</th>\n",
              "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14411</th>\n",
              "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14412 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81efe7f8-cba1-495e-a7f9-c0ae06031a88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81efe7f8-cba1-495e-a7f9-c0ae06031a88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81efe7f8-cba1-495e-a7f9-c0ae06031a88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-42511397-07dc-49e5-abd2-bbae24524ce8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42511397-07dc-49e5-abd2-bbae24524ce8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-42511397-07dc-49e5-abd2-bbae24524ce8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 14412,\n  \"fields\": [\n    {\n      \"column\": \"comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14412,\n        \"samples\": [\n          \"\\u0431\\u0435\\u0437\\u0440\\u043e\\u0434\\u043d\\u044b\\u0439 \\u043f\\u043e\\u0442\\u043e\\u043c\\u043e\\u043a \\u0445\\u043e\\u043b\\u043e\\u043f\\u0430 \\u0440\\u0430\\u0441\\u0441\\u0443\\u0436\\u0434\\u0430\\u0435\\u0442 \\u043e \\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439 \\u0433\\u043e\\u0440\\u0434\\u043e\\u0441\\u0442\\u0438.\\n\",\n          \"\\u0418\\u043d\\u0442\\u0435\\u0440\\u0435\\u0441\\u043d\\u0430\\u044f \\u0442\\u0435\\u043c\\u0430, \\u043e\\u0434\\u043d\\u0430\\u043a\\u043e. \\u041e\\u0422\\u041f \\u0432\\u0440\\u043e\\u0434\\u0435 \\u0432\\u0435\\u043d\\u0433\\u0435\\u0440\\u0441\\u043a\\u0438\\u0439 \\u0431\\u0430\\u043d\\u043a, \\u0432 \\u0412\\u0435\\u043d\\u0433\\u0440\\u0438\\u0438 \\u043e\\u043d \\u0441\\u0430\\u043c\\u044b\\u0439 \\u043f\\u043e\\u043f\\u0443\\u043b\\u044f\\u0440\\u043d\\u044b\\u0439, \\u0443 \\u043c\\u0435\\u043d\\u044f \\u0443 \\u0441\\u0430\\u043c\\u043e\\u0433\\u043e \\u0435\\u0433\\u043e \\u0441\\u0447\\u0451\\u0442 \\u0438 \\u043a\\u0430\\u0440\\u0442\\u0430, \\u0438\\u0431\\u043e \\u0443 \\u043d\\u0435\\u0433\\u043e \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440 \\u0441 \\u0443\\u043d\\u0438\\u0432\\u0435\\u0440\\u043e\\u043c, \\u0441\\u043a\\u0438\\u0434\\u043a\\u0438-\\u043f\\u043b\\u044e\\u0448\\u043a\\u0438-\\u0432\\u043e\\u0437\\u0432\\u0440\\u0430\\u0442 \\u0438 \\u0442.\\u043f. \\u0434\\u043b\\u044f \\u0441\\u0442\\u0443\\u0434\\u0435\\u043d\\u0442\\u043e\\u0432. \\u0418 \\u0437\\u0430 4 \\u0433\\u043e\\u0434\\u0430 \\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u043d\\u0438 \\u043e\\u0434\\u043d\\u043e\\u0439 \\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u044b, \\u043d\\u0438 \\u043e\\u0434\\u043d\\u043e\\u0439 \\u043f\\u043e\\u0434\\u043a\\u043b\\u044e\\u0447\\u0451\\u043d\\u043d\\u043e\\u0439 \\u0443\\u0441\\u043b\\u0443\\u0433\\u0438, \\u0431\\u043b\\u043e\\u043a\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f, \\u0441\\u043f\\u0438\\u0441\\u0430\\u043d\\u0438\\u044f \\u043d\\u0438 \\u0437\\u0430 \\u0447\\u0442\\u043e \\u0438 \\u043f\\u043e\\u0434\\u043e\\u0431\\u043d\\u043e\\u0439 \\u0435\\u0440\\u0435\\u0441\\u0438, \\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0439 \\u0441\\u0442\\u0440\\u0430\\u0434\\u0430\\u044e\\u0442 \\u0432\\u0441\\u0435 \\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0435 \\u0431\\u0430\\u043d\\u043a\\u0438. \\u041d\\u0438\\u043a\\u0430\\u043a\\u0438\\u0445 \\u043a\\u0440\\u0435\\u0434\\u0438\\u0442\\u043d\\u044b\\u0445 \\u043a\\u0430\\u0440\\u0442 \\u0434\\u0430\\u0436\\u0435 \\u043d\\u0435 \\u043f\\u0440\\u0435\\u0434\\u043b\\u0430\\u0433\\u0430\\u044e\\u0442 (\\u0438 \\u0432\\u043e\\u043e\\u0431\\u0449\\u0435 \\u043e \\u043f\\u043e\\u0434\\u043e\\u0431\\u043d\\u044b\\u0445 \\u0438\\u0441\\u0442\\u043e\\u0440\\u0438\\u044f\\u0445 \\u043d\\u0435 \\u0441\\u043b\\u044b\\u0448\\u0430\\u043b). \\u0412\\u044b\\u0445\\u043e\\u0434\\u0438\\u0442, \\u0431\\u0430\\u043d\\u043a \\u0442\\u043e\\u0442 \\u0436\\u0435, \\u0430 \\u043f\\u0440\\u0438\\u043d\\u0446\\u0438\\u043f \\u0440\\u0430\\u0431\\u043e\\u0442\\u044b \\u0434\\u0440\\u0443\\u0433\\u043e\\u0439, \\u0437\\u0430\\u0442\\u043e\\u0447\\u0435\\u043d\\u043d\\u044b\\u0439 \\u043f\\u043e\\u0434 \\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0439 \\u043a\\u043b\\u0438\\u0435\\u043d\\u0442 - \\u043b\\u043e\\u0445 . P.S. \\u0412 \\u0412\\u0435\\u043d\\u0433\\u0440\\u0438\\u0438 \\u0432\\u0441\\u0435 \\u0431\\u0430\\u043d\\u043a\\u0438 \\u0448\\u043b\\u044e\\u0442 \\u043a\\u0430\\u0440\\u0442\\u044b \\u043f\\u043e \\u043f\\u043e\\u0447\\u0442\\u0435, \\u043c\\u043e\\u044f \\u043a\\u0430\\u043a \\u0440\\u0430\\u0437 \\u0432 \\u044d\\u0442\\u043e\\u043c \\u043c\\u0435\\u0441\\u044f\\u0446\\u0435 \\u043f\\u0440\\u0438\\u0448\\u043b\\u0430. \\u041d\\u043e \\u0432 \\u043f\\u043e\\u0447\\u0442\\u043e\\u0432\\u044b\\u0439 \\u044f\\u0449\\u0438\\u043a \\u0438\\u0445 \\u043d\\u0438 \\u0437\\u0430 \\u0447\\u0442\\u043e \\u043d\\u0435 \\u043a\\u0438\\u043d\\u0443\\u0442. \\u041b\\u0438\\u0431\\u043e \\u0432 \\u0440\\u0443\\u043a\\u0438, \\u043b\\u0438\\u0431\\u043e \\u0438\\u0437\\u0432\\u0435\\u0449\\u0435\\u043d\\u0438\\u0435 \\u0447\\u0442\\u043e\\u0431 \\u0437\\u0430\\u0431\\u0440\\u0430\\u043b \\u043d\\u0430 \\u043f\\u043e\\u0447\\u0442\\u0435. \\u0410 \\u043f\\u043e\\u0447\\u0442\\u0430 \\u043f\\u043e\\u0440\\u044f\\u0434\\u043e\\u0447\\u043d\\u0430\\u044f\\n\",\n          \"\\u0421\\u0443\\u0442\\u044c \\u0442\\u0440\\u0435\\u0431\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u043f\\u0440\\u043e \\u041230 - \\u043d\\u0435 \\u043f\\u0440\\u043e\\u0447\\u043d\\u043e\\u0441\\u0442\\u044c, \\u0430 \\u0432\\u043e\\u0434\\u043e\\u043d\\u0435\\u043f\\u0440\\u043e\\u043d\\u0438\\u0446\\u0430\\u0435\\u043c\\u043e\\u0441\\u0442\\u044c. \\u0412\\u043e\\u0434\\u043e\\u043d\\u0435\\u043f\\u0440\\u043e\\u043d\\u0438\\u0446\\u0430\\u0435\\u043c\\u043e\\u0441\\u0442\\u044c \\u0432\\u043e\\u043e\\u0431\\u0449\\u0435 \\u0442\\u043e \\u043e\\u0431\\u043e\\u0437\\u043d\\u0430\\u0447\\u0430\\u0435\\u0442\\u0441\\u044f W, \\u043d\\u0443 \\u0434\\u0430 \\u043d\\u0435 \\u0441\\u0443\\u0442\\u044c, \\u0437\\u0430\\u0447\\u0435\\u043c \\u043c\\u043d\\u0435 \\u043e\\u043d\\u0430 \\u0432 \\u043b\\u0435\\u043d\\u0442\\u0435 \\u043f\\u043e\\u0434 \\u0437\\u0435\\u043c\\u043b\\u0451\\u0439 ?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"toxic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4719578187708464,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts_preprocessed = []\n",
        "for text in tqdm(data['comment']):\n",
        "    tokens = preprocess(text)\n",
        "    texts_preprocessed.append(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akgPjzTyg5Lk",
        "outputId": "7b9ddca7-7824-4f59-dc5c-14f045ca54e4"
      },
      "id": "akgPjzTyg5Lk",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14412/14412 [00:24<00:00, 576.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['tokens'] = texts_preprocessed"
      ],
      "metadata": {
        "id": "QF-pw_bfhPSr"
      },
      "id": "QF-pw_bfhPSr",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "7X-FIxTbh5OB",
        "outputId": "eddb8398-a3f8-44b4-f9d8-d6f506221a0f"
      },
      "id": "7X-FIxTbh5OB",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 comment  toxic  \\\n",
              "0                   Верблюдов-то за что? Дебилы, бл...\\n    1.0   \n",
              "1      Хохлы, это отдушина затюканого россиянина, мол...    1.0   \n",
              "2                              Собаке - собачья смерть\\n    1.0   \n",
              "3      Страницу обнови, дебил. Это тоже не оскорблени...    1.0   \n",
              "4      тебя не убедил 6-страничный пдф в том, что Скр...    1.0   \n",
              "...                                                  ...    ...   \n",
              "14407  Вонючий совковый скот прибежал и ноет. А вот и...    1.0   \n",
              "14408  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0   \n",
              "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0   \n",
              "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0   \n",
              "14411  До сих пор пересматриваю его видео. Орамбо кст...    0.0   \n",
              "\n",
              "                                                  tokens  \n",
              "0                          [верблюд, то, за, что, дебил]  \n",
              "1      [хохол, это, отдушина, затюканый, россиянин, м...  \n",
              "2                              [собака, собачий, смерть]  \n",
              "3      [страница, обновлять, дебил, это, тоже, не, ос...  \n",
              "4      [ты, не, убеждать, страничный, в, то, что, скр...  \n",
              "...                                                  ...  \n",
              "14407  [вонючий, совковый, скот, прибегать, и, ныть, ...  \n",
              "14408  [а, кто, любить, гоблин, тупорылый, что, ли, и...  \n",
              "14409  [посмотреть, утомленный, солнце, и, оказыватьс...  \n",
              "14410  [крымотред, нарушать, правило, раздел, т, к, в...  \n",
              "14411  [до, сей, пора, пересматривать, он, видео, ора...  \n",
              "\n",
              "[14412 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9511ba4d-a23e-41f8-be2a-8b0eb6187364\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[верблюд, то, за, что, дебил]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[хохол, это, отдушина, затюканый, россиянин, м...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[собака, собачий, смерть]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[страница, обновлять, дебил, это, тоже, не, ос...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[ты, не, убеждать, страничный, в, то, что, скр...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14407</th>\n",
              "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[вонючий, совковый, скот, прибегать, и, ныть, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14408</th>\n",
              "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[а, кто, любить, гоблин, тупорылый, что, ли, и...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14409</th>\n",
              "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[посмотреть, утомленный, солнце, и, оказыватьс...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14410</th>\n",
              "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[крымотред, нарушать, правило, раздел, т, к, в...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14411</th>\n",
              "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[до, сей, пора, пересматривать, он, видео, ора...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14412 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9511ba4d-a23e-41f8-be2a-8b0eb6187364')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9511ba4d-a23e-41f8-be2a-8b0eb6187364 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9511ba4d-a23e-41f8-be2a-8b0eb6187364');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-004fac36-4bb2-425e-bd70-6265ada32cff\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-004fac36-4bb2-425e-bd70-6265ada32cff')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-004fac36-4bb2-425e-bd70-6265ada32cff button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 14412,\n  \"fields\": [\n    {\n      \"column\": \"comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14412,\n        \"samples\": [\n          \"\\u0431\\u0435\\u0437\\u0440\\u043e\\u0434\\u043d\\u044b\\u0439 \\u043f\\u043e\\u0442\\u043e\\u043c\\u043e\\u043a \\u0445\\u043e\\u043b\\u043e\\u043f\\u0430 \\u0440\\u0430\\u0441\\u0441\\u0443\\u0436\\u0434\\u0430\\u0435\\u0442 \\u043e \\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439 \\u0433\\u043e\\u0440\\u0434\\u043e\\u0441\\u0442\\u0438.\\n\",\n          \"\\u0418\\u043d\\u0442\\u0435\\u0440\\u0435\\u0441\\u043d\\u0430\\u044f \\u0442\\u0435\\u043c\\u0430, \\u043e\\u0434\\u043d\\u0430\\u043a\\u043e. \\u041e\\u0422\\u041f \\u0432\\u0440\\u043e\\u0434\\u0435 \\u0432\\u0435\\u043d\\u0433\\u0435\\u0440\\u0441\\u043a\\u0438\\u0439 \\u0431\\u0430\\u043d\\u043a, \\u0432 \\u0412\\u0435\\u043d\\u0433\\u0440\\u0438\\u0438 \\u043e\\u043d \\u0441\\u0430\\u043c\\u044b\\u0439 \\u043f\\u043e\\u043f\\u0443\\u043b\\u044f\\u0440\\u043d\\u044b\\u0439, \\u0443 \\u043c\\u0435\\u043d\\u044f \\u0443 \\u0441\\u0430\\u043c\\u043e\\u0433\\u043e \\u0435\\u0433\\u043e \\u0441\\u0447\\u0451\\u0442 \\u0438 \\u043a\\u0430\\u0440\\u0442\\u0430, \\u0438\\u0431\\u043e \\u0443 \\u043d\\u0435\\u0433\\u043e \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440 \\u0441 \\u0443\\u043d\\u0438\\u0432\\u0435\\u0440\\u043e\\u043c, \\u0441\\u043a\\u0438\\u0434\\u043a\\u0438-\\u043f\\u043b\\u044e\\u0448\\u043a\\u0438-\\u0432\\u043e\\u0437\\u0432\\u0440\\u0430\\u0442 \\u0438 \\u0442.\\u043f. \\u0434\\u043b\\u044f \\u0441\\u0442\\u0443\\u0434\\u0435\\u043d\\u0442\\u043e\\u0432. \\u0418 \\u0437\\u0430 4 \\u0433\\u043e\\u0434\\u0430 \\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u043d\\u0438 \\u043e\\u0434\\u043d\\u043e\\u0439 \\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u044b, \\u043d\\u0438 \\u043e\\u0434\\u043d\\u043e\\u0439 \\u043f\\u043e\\u0434\\u043a\\u043b\\u044e\\u0447\\u0451\\u043d\\u043d\\u043e\\u0439 \\u0443\\u0441\\u043b\\u0443\\u0433\\u0438, \\u0431\\u043b\\u043e\\u043a\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f, \\u0441\\u043f\\u0438\\u0441\\u0430\\u043d\\u0438\\u044f \\u043d\\u0438 \\u0437\\u0430 \\u0447\\u0442\\u043e \\u0438 \\u043f\\u043e\\u0434\\u043e\\u0431\\u043d\\u043e\\u0439 \\u0435\\u0440\\u0435\\u0441\\u0438, \\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0439 \\u0441\\u0442\\u0440\\u0430\\u0434\\u0430\\u044e\\u0442 \\u0432\\u0441\\u0435 \\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0435 \\u0431\\u0430\\u043d\\u043a\\u0438. \\u041d\\u0438\\u043a\\u0430\\u043a\\u0438\\u0445 \\u043a\\u0440\\u0435\\u0434\\u0438\\u0442\\u043d\\u044b\\u0445 \\u043a\\u0430\\u0440\\u0442 \\u0434\\u0430\\u0436\\u0435 \\u043d\\u0435 \\u043f\\u0440\\u0435\\u0434\\u043b\\u0430\\u0433\\u0430\\u044e\\u0442 (\\u0438 \\u0432\\u043e\\u043e\\u0431\\u0449\\u0435 \\u043e \\u043f\\u043e\\u0434\\u043e\\u0431\\u043d\\u044b\\u0445 \\u0438\\u0441\\u0442\\u043e\\u0440\\u0438\\u044f\\u0445 \\u043d\\u0435 \\u0441\\u043b\\u044b\\u0448\\u0430\\u043b). \\u0412\\u044b\\u0445\\u043e\\u0434\\u0438\\u0442, \\u0431\\u0430\\u043d\\u043a \\u0442\\u043e\\u0442 \\u0436\\u0435, \\u0430 \\u043f\\u0440\\u0438\\u043d\\u0446\\u0438\\u043f \\u0440\\u0430\\u0431\\u043e\\u0442\\u044b \\u0434\\u0440\\u0443\\u0433\\u043e\\u0439, \\u0437\\u0430\\u0442\\u043e\\u0447\\u0435\\u043d\\u043d\\u044b\\u0439 \\u043f\\u043e\\u0434 \\u0440\\u043e\\u0441\\u0441\\u0438\\u0439\\u0441\\u043a\\u0438\\u0439 \\u043a\\u043b\\u0438\\u0435\\u043d\\u0442 - \\u043b\\u043e\\u0445 . P.S. \\u0412 \\u0412\\u0435\\u043d\\u0433\\u0440\\u0438\\u0438 \\u0432\\u0441\\u0435 \\u0431\\u0430\\u043d\\u043a\\u0438 \\u0448\\u043b\\u044e\\u0442 \\u043a\\u0430\\u0440\\u0442\\u044b \\u043f\\u043e \\u043f\\u043e\\u0447\\u0442\\u0435, \\u043c\\u043e\\u044f \\u043a\\u0430\\u043a \\u0440\\u0430\\u0437 \\u0432 \\u044d\\u0442\\u043e\\u043c \\u043c\\u0435\\u0441\\u044f\\u0446\\u0435 \\u043f\\u0440\\u0438\\u0448\\u043b\\u0430. \\u041d\\u043e \\u0432 \\u043f\\u043e\\u0447\\u0442\\u043e\\u0432\\u044b\\u0439 \\u044f\\u0449\\u0438\\u043a \\u0438\\u0445 \\u043d\\u0438 \\u0437\\u0430 \\u0447\\u0442\\u043e \\u043d\\u0435 \\u043a\\u0438\\u043d\\u0443\\u0442. \\u041b\\u0438\\u0431\\u043e \\u0432 \\u0440\\u0443\\u043a\\u0438, \\u043b\\u0438\\u0431\\u043e \\u0438\\u0437\\u0432\\u0435\\u0449\\u0435\\u043d\\u0438\\u0435 \\u0447\\u0442\\u043e\\u0431 \\u0437\\u0430\\u0431\\u0440\\u0430\\u043b \\u043d\\u0430 \\u043f\\u043e\\u0447\\u0442\\u0435. \\u0410 \\u043f\\u043e\\u0447\\u0442\\u0430 \\u043f\\u043e\\u0440\\u044f\\u0434\\u043e\\u0447\\u043d\\u0430\\u044f\\n\",\n          \"\\u0421\\u0443\\u0442\\u044c \\u0442\\u0440\\u0435\\u0431\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u043f\\u0440\\u043e \\u041230 - \\u043d\\u0435 \\u043f\\u0440\\u043e\\u0447\\u043d\\u043e\\u0441\\u0442\\u044c, \\u0430 \\u0432\\u043e\\u0434\\u043e\\u043d\\u0435\\u043f\\u0440\\u043e\\u043d\\u0438\\u0446\\u0430\\u0435\\u043c\\u043e\\u0441\\u0442\\u044c. \\u0412\\u043e\\u0434\\u043e\\u043d\\u0435\\u043f\\u0440\\u043e\\u043d\\u0438\\u0446\\u0430\\u0435\\u043c\\u043e\\u0441\\u0442\\u044c \\u0432\\u043e\\u043e\\u0431\\u0449\\u0435 \\u0442\\u043e \\u043e\\u0431\\u043e\\u0437\\u043d\\u0430\\u0447\\u0430\\u0435\\u0442\\u0441\\u044f W, \\u043d\\u0443 \\u0434\\u0430 \\u043d\\u0435 \\u0441\\u0443\\u0442\\u044c, \\u0437\\u0430\\u0447\\u0435\\u043c \\u043c\\u043d\\u0435 \\u043e\\u043d\\u0430 \\u0432 \\u043b\\u0435\\u043d\\u0442\\u0435 \\u043f\\u043e\\u0434 \\u0437\\u0435\\u043c\\u043b\\u0451\\u0439 ?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"toxic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4719578187708464,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embedding(tokens, model):\n",
        "    embeddings = []\n",
        "    for token in tokens:\n",
        "        if token in model.wv:\n",
        "            embeddings.append(model.wv[token])\n",
        "\n",
        "    if len(embeddings) == 0:\n",
        "        return np.zeros(model.wv.vector_size)\n",
        "\n",
        "    return np.mean(embeddings, axis=0)"
      ],
      "metadata": {
        "id": "359Hsl2ehr9P"
      },
      "id": "359Hsl2ehr9P",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_w2v = []\n",
        "for tokens in tqdm(data['tokens']):\n",
        "    emb = get_text_embedding(tokens, w2v)\n",
        "    X_w2v.append(emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KO5OG5-h_Yh",
        "outputId": "4b69e948-3697-49d5-e030-90f7e5bfc46a"
      },
      "id": "2KO5OG5-h_Yh",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14412/14412 [00:01<00:00, 11285.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_w2v = np.array(X_w2v)\n",
        "y = data['toxic'].values"
      ],
      "metadata": {
        "id": "GD-OGBBjiHMA"
      },
      "id": "GD-OGBBjiHMA",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_w2v, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "OWDBGhRHiMt8"
      },
      "id": "OWDBGhRHiMt8",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "b2Vecfc0iVWX"
      },
      "id": "b2Vecfc0iVWX",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "uASu6rX-iQTF",
        "outputId": "1b760e07-a9c1-4b9f-98e1-77c8513c281b"
      },
      "id": "uASu6rX-iQTF",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "jhzPCBnYiZzs"
      },
      "id": "jhzPCBnYiZzs",
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1-score на тестовой выборке: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8yKVM9qikSx",
        "outputId": "3ee3b26a-3e17-477f-bcce-2a8f3dae1162"
      },
      "id": "m8yKVM9qikSx",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score на тестовой выборке: 0.6555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=['non-toxic', 'toxic']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r3lkzS7iu2C",
        "outputId": "15ee0aea-b7cb-4955-cb2f-b27fd1905c0b"
      },
      "id": "_r3lkzS7iu2C",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   non-toxic       0.81      0.89      0.85      1918\n",
            "       toxic       0.74      0.59      0.66       965\n",
            "\n",
            "    accuracy                           0.79      2883\n",
            "   macro avg       0.77      0.74      0.75      2883\n",
            "weighted avg       0.79      0.79      0.79      2883\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60c18c5a",
      "metadata": {
        "id": "60c18c5a"
      },
      "source": [
        "# Задание 4 (2 доп балла)\n",
        "\n",
        "В тетрадку с фастекстом добавьте код для обучения с negative sampling (задача сводится к бинарной классификации) и обучите модель. Проверьте полученную модель на нескольких словах. Похожие слова должны быть похожими по смыслу и по форме."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "d437a8c0",
      "metadata": {
        "id": "d437a8c0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "def tokenize(text):\n",
        "    tokens = re.sub('#+', ' ', text.lower()).split()\n",
        "    tokens = [token.strip(punctuation) for token in tokens]\n",
        "    tokens = [token for token in tokens if token]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "RMuUH8rdmy6k"
      },
      "id": "RMuUH8rdmy6k",
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ngrammer(raw_string, n=2):\n",
        "    ngrams = []\n",
        "    raw_string = ''.join(['<', raw_string, '>'])\n",
        "    for i in range(0,len(raw_string)-n+1):\n",
        "        ngram = ''.join(raw_string[i:i+n])\n",
        "        if ngram == '<' or ngram == '>':\n",
        "            continue\n",
        "        ngrams.append(ngram)\n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "JrHdRB-lm1vB"
      },
      "id": "JrHdRB-lm1vB",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_tokens(tokens, min_ngram_size, max_ngram_size):\n",
        "    tokens_with_subwords = []\n",
        "    for token in tokens:\n",
        "        subtokens = []\n",
        "        for i in range(min_ngram_size, max_ngram_size+1):\n",
        "            if len(token) > i:\n",
        "                subtokens.extend(ngrammer(token, i))\n",
        "        tokens_with_subwords.append(subtokens)\n",
        "    return tokens_with_subwords"
      ],
      "metadata": {
        "id": "uNqyfg18m4qS"
      },
      "id": "uNqyfg18m4qS",
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SubwordTokenizer:\n",
        "    def __init__(self, ngram_range=(1,1), min_count=5):\n",
        "        self.min_ngram_size, self.max_ngram_size = ngram_range\n",
        "        self.min_count = min_count\n",
        "        self.subword_vocab = None\n",
        "        self.fullword_vocab = None\n",
        "        self.vocab = None\n",
        "        self.id2word = None\n",
        "        self.word2id = None\n",
        "\n",
        "    def build_vocab(self, texts):\n",
        "        # чтобы построить словарь нужно пройти по всему корпусу и собрать частоты всех уникальных слов и нграммов\n",
        "        unfiltered_subword_vocab = Counter()\n",
        "        unfiltered_fullword_vocab = Counter()\n",
        "        for text in texts:\n",
        "            tokens = tokenize(text)\n",
        "            unfiltered_fullword_vocab.update(tokens)\n",
        "            subwords_per_token = split_tokens(tokens, self.min_ngram_size, self.max_ngram_size)\n",
        "            for subwords in subwords_per_token:\n",
        "                # в одном слове могут быть одинаковые нграммы поэтому возьмем только уникальные\n",
        "                unfiltered_subword_vocab.update(set(subwords))\n",
        "\n",
        "        self.fullword_vocab = set()\n",
        "        self.subword_vocab = set()\n",
        "\n",
        "        # теперь отфильтруем по частоте\n",
        "        for word, count in unfiltered_fullword_vocab.items():\n",
        "            if count >= self.min_count:\n",
        "                self.fullword_vocab.add(word)\n",
        "        # для нграммов сделаем порог побольше чтобы не создавать слишком много нграммов\n",
        "        # и учитывать только действительно частотные\n",
        "        for word, count in unfiltered_subword_vocab.items():\n",
        "            if count >= (self.min_count * 100):\n",
        "                self.subword_vocab.add(word)\n",
        "\n",
        "        # общий словарь\n",
        "        self.vocab = self.fullword_vocab | self.subword_vocab\n",
        "        self.id2word = {i:word for i,word in enumerate(self.vocab)}\n",
        "        self.word2id = {word:i for i,word in self.id2word.items()}\n",
        "\n",
        "    def subword_tokenize(self, text):\n",
        "        if self.vocab is None:\n",
        "            raise AttributeError('Vocabulary is not built!')\n",
        "        # разбиваем на токены\n",
        "        tokens = tokenize(text)\n",
        "        # каждый токен разбиваем на символьные нграммы\n",
        "        tokens_with_subwords = split_tokens(tokens, self.min_ngram_size, self.max_ngram_size)\n",
        "        # оставляет только токены и нграммы которые есть в словаре\n",
        "        only_vocab_tokens_with_subwords = []\n",
        "        for full_token, sub_tokens in zip(tokens, tokens_with_subwords):\n",
        "            filtered = []\n",
        "            if full_token in self.vocab:\n",
        "                # само слово и нграммы хранятся в одном списке\n",
        "                # но слово будет всегда первым в списке\n",
        "                filtered.append(full_token)\n",
        "            filtered.extend([subtoken for subtoken in set(sub_tokens) if subtoken in self.vocab])\n",
        "            only_vocab_tokens_with_subwords.append(filtered)\n",
        "\n",
        "        return only_vocab_tokens_with_subwords\n",
        "\n",
        "    def encode(self, subword_tokenized_text):\n",
        "        # маппим токены и нграммы в их индексы в словаре\n",
        "        encoded_text = []\n",
        "        for token in subword_tokenized_text:\n",
        "            if not token:\n",
        "                continue\n",
        "            encoded_text.append([self.word2id[token[0]]] + [self.word2id[t] for t in set(token[1:]) if t in self.word2id and t != token[0]])\n",
        "        return encoded_text\n",
        "\n",
        "    def __call__(self, text):\n",
        "        return self.encode(self.subword_tokenize(text))"
      ],
      "metadata": {
        "id": "GwJkIvmQm7kt"
      },
      "id": "GwJkIvmQm7kt",
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SubwordTokenizer(ngram_range=(2,4), min_count=10)\n",
        "tokenizer.build_vocab(wiki)"
      ],
      "metadata": {
        "id": "pFuXxosLmRlA"
      },
      "id": "pFuXxosLmRlA",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_batches_ft_neg_sampling(sentences, tokenizer, window=5, batch_size=1000,\n",
        "                                 maxlen=20, num_negative=5):\n",
        "\n",
        "    left_context_length = (window/2).__ceil__()\n",
        "    right_context_length = window // 2\n",
        "    vocab_size = len(tokenizer.fullword_vocab)\n",
        "\n",
        "    while True:\n",
        "        X = []\n",
        "        y_context = []\n",
        "        labels = []\n",
        "\n",
        "        for sent in sentences:\n",
        "            sent_encoded = tokenizer(sent)\n",
        "            for i in range(len(sent_encoded)-1):\n",
        "                word_with_subtokens = sent_encoded[i]\n",
        "                context = sent_encoded[max(0, i-left_context_length):i] + \\\n",
        "                         sent_encoded[i+1:i+right_context_length+1]\n",
        "\n",
        "                for context_word_with_subtokens in context:\n",
        "                    only_full_word_context_token = context_word_with_subtokens[0]\n",
        "\n",
        "                    X.append(word_with_subtokens)\n",
        "                    y_context.append(only_full_word_context_token)\n",
        "                    labels.append(1.0)\n",
        "\n",
        "                    for _ in range(num_negative):\n",
        "                        neg_context = np.random.randint(vocab_size)\n",
        "                        X.append(word_with_subtokens)\n",
        "                        y_context.append(neg_context)\n",
        "                        labels.append(0.0)\n",
        "\n",
        "                    if len(X) >= batch_size:\n",
        "                        X_arr = pad_sequences(X[:batch_size], maxlen=maxlen, padding='post', value=0)\n",
        "                        y_arr = np.array(y_context[:batch_size], dtype='int64')\n",
        "                        labels_arr = np.array(labels[:batch_size], dtype='float32')\n",
        "                        yield (X_arr, y_arr, labels_arr)\n",
        "                        X = X[batch_size:]\n",
        "                        y_context = y_context[batch_size:]\n",
        "                        labels = labels[batch_size:]"
      ],
      "metadata": {
        "id": "2k50fM4imJ5C"
      },
      "id": "2k50fM4imJ5C",
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FastTextNegSampling(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "\n",
        "    def forward(self, X_center, X_context):\n",
        "        center_embs = self.emb(X_center)  # (batch, maxlen, emb_dim)\n",
        "\n",
        "        mask = (X_center != 0).float().unsqueeze(-1)  # (batch, maxlen, 1)\n",
        "        center_embs = (center_embs * mask).sum(dim=1)  # (batch, emb_dim)\n",
        "        count = mask.sum(dim=1).clamp(min=1)  # (batch, 1)\n",
        "        center_embs = center_embs / count  # усредняем\n",
        "\n",
        "        context_embs = self.emb(X_context)  # (batch, emb_dim)\n",
        "        dot = (center_embs * context_embs).sum(dim=1)  # (batch,)\n",
        "\n",
        "        return dot"
      ],
      "metadata": {
        "id": "wAAulfiTmYg9"
      },
      "id": "wAAulfiTmYg9",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.vocab)\n",
        "emb_dim = 100\n",
        "window = 5\n",
        "batch_size = 1000\n",
        "num_negative = 5\n",
        "num_epochs = 10\n",
        "steps_per_epoch = 1000\n",
        "\n",
        "\n",
        "model = FastTextNegSampling(vocab_size, emb_dim).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "train_gen = gen_batches_ft_neg_sampling(\n",
        "    wiki[:19000], tokenizer,\n",
        "    window=window,\n",
        "    batch_size=batch_size,\n",
        "    num_negative=num_negative\n",
        ")\n",
        "val_gen = gen_batches_ft_neg_sampling(\n",
        "    wiki[19000:], tokenizer,\n",
        "    window=window,\n",
        "    batch_size=batch_size,\n",
        "    num_negative=num_negative\n",
        ")"
      ],
      "metadata": {
        "id": "RlM2EuYCmiEK"
      },
      "id": "RlM2EuYCmiEK",
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for step in tqdm(range(steps_per_epoch), desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        X, y_context, labels = next(train_gen)\n",
        "        X = torch.LongTensor(X).to(device)\n",
        "        y_context = torch.LongTensor(y_context).to(device)\n",
        "        labels = torch.FloatTensor(labels).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(X, y_context)\n",
        "        loss = criterion(scores, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= steps_per_epoch\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    validation_steps = 50\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step in range(validation_steps):\n",
        "            X, y_context, labels = next(val_gen)\n",
        "            X = torch.LongTensor(X).to(device)\n",
        "            y_context = torch.LongTensor(y_context).to(device)\n",
        "            labels = torch.FloatTensor(labels).to(device)\n",
        "\n",
        "            scores = model(X, y_context)\n",
        "            loss = criterion(scores, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= validation_steps\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - train loss: {epoch_loss:.4f}, val loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXy9qpTCneFh",
        "outputId": "c387fb4b-39cc-4bb4-80cb-a57a29791c53"
      },
      "id": "wXy9qpTCneFh",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 1000/1000 [00:11<00:00, 90.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - train loss: 1.6687, val loss: 1.4187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 1000/1000 [00:09<00:00, 106.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 - train loss: 1.4156, val loss: 1.3345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 1000/1000 [00:08<00:00, 114.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 - train loss: 1.2436, val loss: 1.1677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 1000/1000 [00:09<00:00, 106.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 - train loss: 1.0752, val loss: 1.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 1000/1000 [00:09<00:00, 105.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 - train loss: 0.8950, val loss: 0.8177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 1000/1000 [00:09<00:00, 100.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 - train loss: 0.7410, val loss: 0.6771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 1000/1000 [00:09<00:00, 101.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 - train loss: 0.6098, val loss: 0.5805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 1000/1000 [00:08<00:00, 116.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 - train loss: 0.5265, val loss: 0.5051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 1000/1000 [00:10<00:00, 92.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 - train loss: 0.4704, val loss: 0.4790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 1000/1000 [00:10<00:00, 94.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 - train loss: 0.4460, val loss: 0.4246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "embeddings = model.emb.weight.detach().cpu().numpy()\n",
        "\n",
        "full_word_embeddings = np.zeros((len(tokenizer.fullword_vocab), emb_dim))\n",
        "id2word = list(tokenizer.fullword_vocab)\n",
        "\n",
        "for i, word in enumerate(tokenizer.fullword_vocab):\n",
        "    subwords = tokenizer(word)[0]\n",
        "    if subwords:\n",
        "        full_word_embeddings[i] = embeddings[[idx for idx in subwords]].mean(axis=0)"
      ],
      "metadata": {
        "id": "DkROxIUNnrPM"
      },
      "id": "DkROxIUNnrPM",
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar_ft(word, embeddings, tokenizer, topk=10):\n",
        "    subwords = tokenizer(word)[0]\n",
        "    word_embedding = embeddings[[i for i in subwords]].sum(axis=0)\n",
        "    similar = [id2word[i] for i in\n",
        "               cosine_distances(word_embedding.reshape(1, -1), full_word_embeddings).argsort()[0][:20]]\n",
        "    return similar[:topk]"
      ],
      "metadata": {
        "id": "GtCVdVx_oxoh"
      },
      "id": "GtCVdVx_oxoh",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(f'Слово: {word}\\n\\t{most_similar_ft(word, embeddings, tokenizer, topk=10)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQen1ZjypDE_",
        "outputId": "95f85c6b-20bc-47ee-fa31-29e1b4da470a"
      },
      "id": "iQen1ZjypDE_",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слово: философия\n",
            "\t['философия', 'философию', 'философией', 'философы', 'философии', 'философ', 'философа', 'философов', 'философских', 'философии»']\n",
            "Слово: болезнь\n",
            "\t['болезнь', 'болезнях', 'болезни»', 'болезни', 'болезнями', 'болезнью', 'болезней', 'полезно', 'болота', 'инновационный']\n",
            "Слово: музыка\n",
            "\t['музыка', 'музыка»', 'музыку', 'музыкальные', 'музыкант', 'музыкальной', 'музыкальных', 'музыки»', 'музыкальном', 'музыке']\n",
            "Слово: машина\n",
            "\t['машина', 'машинах', 'машин', 'машинами', 'машине', 'машиниста', 'машиностроение', 'машиностроения', 'машиной', 'части']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Больше акцент на форму получается, а если формы заканчивается, то \"вылезают\" абсолютно непонятные слова: \"болезнь\" –> \"полезно\" / \"инновационный\""
      ],
      "metadata": {
        "id": "ZSIvbLqqqEhb"
      },
      "id": "ZSIvbLqqqEhb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}